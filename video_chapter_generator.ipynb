{
 "cells": [
  {
   "metadata": {
    "id": "936b8576d21f6578"
   },
   "cell_type": "markdown",
   "source": [
    "# Automatic video chaptering with LLMs and TF-IDF\n",
    " \n",
    "- Accompanying Medium article: [Automatic video chaptering with LLMs and TF-IDF]()\n",
    "- [Github repository](https://github.com/Yannael/automatic-video-chaptering)\n",
    "- [Gradio demo on HuggingFace](https://huggingface.co/spaces/Yannael/video-chaptering)\n"
   ],
   "id": "936b8576d21f6578"
  },
  {
   "metadata": {
    "id": "4b2ce387523e8767"
   },
   "cell_type": "markdown",
   "source": [
    "# Install and import libraries\n",
    "\n",
    "This notebook makes use of the following libraries:\n",
    "\n",
    "- `youtube-transcript-api`: used to directly download the video transcript from Youtube\n",
    "- `openai` and `groq`: used to interact with LLMs (Llama 3 8B or GPT-4o-mini)\n",
    "- `gradio`: used to create a simple web interface to interact with the model\n",
    "\n",
    "Optional libraries (for video downloading and speech-to-text Whisper model)\n",
    "\n",
    "- `yt-dlp`: used to download the audio of a Youtube video\n",
    "- `faster_whisper`: used to get transcript from audio\n"
   ],
   "id": "4b2ce387523e8767"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Install libraries with:",
   "id": "2184361d0bba7580"
  },
  {
   "metadata": {
    "id": "145a6d764975a065",
    "ExecuteTime": {
     "end_time": "2024-07-29T11:53:39.403232Z",
     "start_time": "2024-07-29T11:53:24.331135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "!pip install -q youtube-transcript-api\n",
    "!pip install -q openai\n",
    "!pip install -q groq\n",
    "!pip install -q gradio\n",
    "\n",
    "!pip install -q yt_dlp\n",
    "!pip install -q faster_whisper\n"
   ],
   "id": "145a6d764975a065",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "d3b292af3e8a9ebc"
   },
   "cell_type": "markdown",
   "source": "Load libraries\n",
   "id": "d3b292af3e8a9ebc"
  },
  {
   "metadata": {
    "id": "e385bd173a3f98b5",
    "ExecuteTime": {
     "end_time": "2024-09-09T07:30:29.577391Z",
     "start_time": "2024-09-09T07:30:27.038072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import re \n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import yt_dlp\n",
    "from faster_whisper import WhisperModel\n",
    "import torch\n",
    "\n",
    "# Load your keys from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Or add your keys here\n",
    "# GROQ_API_KEY = \"xxx\"\n",
    "# OPENAI_API_KEY = \"xxx\""
   ],
   "id": "e385bd173a3f98b5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define Youtube video ID, folder to store video, chapters, and resulting blog post.\n",
   "id": "f242a429e47c7295"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T07:30:38.274020Z",
     "start_time": "2024-09-09T07:30:38.272103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Usage example\n",
    "video_id = 'ErnWZxJovaM' # MIT Introduction to Deep Learning | 6.S191 - Alexander Amini\n",
    "#video_id = 'Unzc731iCUY' # How to speak - Patrick Winston - https://www.youtube.com/watch?v=Unzc731iCUY\n",
    "#video_id = 'zduSFxRajkE' # Let's build the GPT Tokenizer - Andrej Karpathy\n",
    "\n",
    "DATA_DIR = f\"examples/{video_id}\"\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n"
   ],
   "id": "b459f93788c9de66",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "190c9725641aa431"
   },
   "cell_type": "markdown",
   "source": [
    "## 1) Get the video/audio transcript\n",
    "\n"
   ],
   "id": "190c9725641aa431"
  },
  {
   "metadata": {
    "id": "f3abeccf47cdbca"
   },
   "cell_type": "markdown",
   "source": [
    "### With YouTubeTranscriptApi"
   ],
   "id": "f3abeccf47cdbca"
  },
  {
   "metadata": {
    "id": "aa251880011c435d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0446799a-c103-445e-9151-603083f8cb1c",
    "ExecuteTime": {
     "end_time": "2024-09-09T07:30:40.860149Z",
     "start_time": "2024-09-09T07:30:39.941279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
    "transcript = [{'start': s['start'], 'text': s['text']} for s in transcript]\n",
    "transcript[0:4]"
   ],
   "id": "aa251880011c435d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 1.17, 'text': '[Music]'},\n",
       " {'start': 10.28, 'text': 'good afternoon everyone and welcome to'},\n",
       " {'start': 12.88, 'text': 'MIT sus1 191 my name is Alexander amini'},\n",
       " {'start': 16.84, 'text': \"and I'll be one of your instructors for\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "cb1e8698e477d6da",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "459233d7-7e81-478b-876e-f7d3e1e23445",
    "ExecuteTime": {
     "end_time": "2024-09-09T07:30:41.780164Z",
     "start_time": "2024-09-09T07:30:41.777050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "len(transcript)"
   ],
   "id": "cb1e8698e477d6da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1789"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "id": "b6866413017a00cf"
   },
   "cell_type": "markdown",
   "source": [
    "### With Whisper\n",
    "\n"
   ],
   "id": "b6866413017a00cf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Download audio"
   ],
   "metadata": {
    "id": "Y5FHy9st98S0"
   },
   "id": "Y5FHy9st98S0"
  },
  {
   "cell_type": "code",
   "source": [
    "def download_audio(video_id, DOWNLOAD_DIR=\"temp_download\"):\n",
    "\n",
    "    os.makedirs(f\"{DOWNLOAD_DIR}\", exist_ok=True)\n",
    "    os.makedirs(f\"{DOWNLOAD_DIR}/{video_id}\", exist_ok=True)\n",
    "\n",
    "    audio_path = f\"{DOWNLOAD_DIR}/{video_id}/{video_id}_audio.mp4\"\n",
    "\n",
    "    # Define options for yt-dlp\n",
    "    ydl_opts = {\n",
    "        'format': f'bestaudio',  # Select the best quality format\n",
    "        'outtmpl': audio_path\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        video_url = 'https://www.youtube.com/watch?v=' + video_id\n",
    "        ydl.download([video_url])\n",
    "\n",
    "\n",
    "    return audio_path\n",
    "\n",
    "# About 5 seconds for a one hour video (65MB of audio)\n",
    "#%time \n",
    "path_to_audio=download_audio(video_id, DATA_DIR)"
   ],
   "metadata": {
    "id": "wQne_n-Z9_pL",
    "ExecuteTime": {
     "end_time": "2024-08-28T18:25:15.928120Z",
     "start_time": "2024-08-28T18:25:09.567409Z"
    }
   },
   "id": "wQne_n-Z9_pL",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=xv7oV1QD3sE\n",
      "[youtube] xv7oV1QD3sE: Downloading webpage\n",
      "[youtube] xv7oV1QD3sE: Downloading ios player API JSON\n",
      "[youtube] xv7oV1QD3sE: Downloading android player API JSON\n",
      "[youtube] xv7oV1QD3sE: Downloading player bcd1f224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] xv7oV1QD3sE: nsig extraction failed: You may experience throttling for some formats\n",
      "         n = kGAfTKXzUyorHLTMUm ; player = https://www.youtube.com/s/player/bcd1f224/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] xv7oV1QD3sE: nsig extraction failed: You may experience throttling for some formats\n",
      "         n = U0aww6VcNcAgDLX1WW ; player = https://www.youtube.com/s/player/bcd1f224/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] xv7oV1QD3sE: Downloading m3u8 information\n",
      "[info] xv7oV1QD3sE: Downloading 1 format(s): 140\n",
      "[download] Destination: tmp/xv7oV1QD3sE/xv7oV1QD3sE/xv7oV1QD3sE_audio.mp4\n",
      "[download] 100% of   41.05MiB in 00:00:01 at 28.54MiB/s    \n",
      "[FixupM4a] Correcting container of \"tmp/xv7oV1QD3sE/xv7oV1QD3sE/xv7oV1QD3sE_audio.mp4\"\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Transcribe with Whisper"
   ],
   "metadata": {
    "id": "XdYFA0Sj9_0l"
   },
   "id": "XdYFA0Sj9_0l"
  },
  {
   "metadata": {
    "id": "cbbc9b50c4da22fd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307,
     "referenced_widgets": [
      "0a0ac81d2d3441e9b3a5df76a1bd2554",
      "625a356a3c03490e94fd7fd4c6735dd5",
      "9eae25c0de28460d8eda4c81f36b12c8",
      "7aaeb859fd084de5a9e0a6a8c457530d",
      "638b115d08bb4367a18d8cb83be3eaba",
      "b85add037e794592a3d10faafed14769",
      "e6593af0c76145cb95e70163d8b7aa79",
      "a037da54f3af40e6a8f2762d39c9223d",
      "e29b8ba4a5034817a48d2467424f922b",
      "3990513292034aafae131b8045a203e9",
      "c1da0bb480624ff0b39f7dd9fc5f9d0e",
      "575173787b5c4eb1b445d2dec7bae387",
      "1ec2b1f01be44544bf5a4cb59f4e7499",
      "17a44e75a6414564b01a9f053ebe8687",
      "11b80bf54a9e42bc99d936b63b464dba",
      "95a2cbd3dfe346d4a4d5337389a644f2",
      "9fe82db2540845f985804af8c3712c40",
      "12cc093257a5494fa42b75977e79d62c",
      "328692e5bc6d40178ecc999b374f7632",
      "593ff4c702d3449fb4f548bdddbb6977",
      "974273a5cbb64630b28f49f4622181f1",
      "f19d9c65f1cf4af893d71fb2189beb5d",
      "d9346d22a11e4a5dbfc8e265d7603c4d",
      "bdb99e3a45464eb4a52d00538f5db3b9",
      "7391cc19998e426288d31a3ad58b67b1",
      "7b8979ebd440484aa62c64a70a95b585",
      "ef51ff208ad54d5880fe097273503134",
      "87fa8610eb184d06a5fa2525e0221fbf",
      "7856dd4417c14c76afd1b8fb3aa2d151",
      "f6c93bc03f6d4573913b489a73694c54",
      "362358622d4047e8b1fb24a958315a02",
      "25747c9a3e3e47bc8d1067d65026fa22",
      "9e99c0ed5ccb4de9bc67c77d2e805a8a",
      "de6bb81359e74ab3b26d3ab321d7c789",
      "20b2418166fa4d0caa928ac2d390ad78",
      "2b5f0fd2b89c48ebb1b5487691f35411",
      "feca3fad25ac4c4d8c71a3189f0ef1f7",
      "69efc6afcfd444ae9ecb9ca5e70e0d5f",
      "2827314ccbdc49079e3fea36c335b588",
      "8329efacee6b4d0bb321b11d56a357c7",
      "92b5ded7cbf4467086af505723ad4e6d",
      "a19f4a06f3374e568acb51007656cea2",
      "6ad99df8f8b244b3861a49cd66a8de9c",
      "160bcbf3fc7e47aa83ac839dcef9e542",
      "24a4c950d74a41f29bf8b074dbc2997f",
      "ed5fa7711fac4e08b9f3882a269dd612",
      "ca7e477fbecd4d00b29db417663d5d54",
      "4bc292ec121c432f8ce0d71b70c37e30",
      "7d596ba8913842a1ba53a37d3b4d6728",
      "d5dbed46f7844ea6851b42af3766470f",
      "ce34ab0c3707422090e4f801fd927805",
      "e5e7b727f99e4df4a2cc890771230d2f",
      "bb4794ca6cf742b3880fd16cb26ad28d",
      "090f3982133a4bb38a41cae71300389a",
      "a552975238a944d8a50d1ddf9400c287"
     ]
    },
    "outputId": "852fc5e0-0e3f-43f2-df60-3b4514838aa8"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a0ac81d2d3441e9b3a5df76a1bd2554"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/2.39k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "575173787b5c4eb1b445d2dec7bae387"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9346d22a11e4a5dbfc8e265d7603c4d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de6bb81359e74ab3b26d3ab321d7c789"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocabulary.json:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24a4c950d74a41f29bf8b074dbc2997f"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": null,
   "source": [
    "whisper_model = WhisperModel(\"large-v3\",\n",
    "                              device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                              compute_type=\"float16\",\n",
    "                            )"
   ],
   "id": "cbbc9b50c4da22fd"
  },
  {
   "metadata": {
    "id": "d3ca9c90b82fa755"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def speech_to_text(whisper_model, audio_file, initial_prompt=\"Use punctuation, like this.\", language=\"en\", segments=None):\n",
    "\n",
    "        segments, transcript_info = whisper_model.transcribe(audio_file,  initial_prompt=initial_prompt, language=language)\n",
    "        segments = list(segments)\n",
    "        segments = [\n",
    "            {\n",
    "                \"start\": round(s.start,2),\n",
    "                \"duration\": round(s.end-s.start,2),\n",
    "                \"text\": s.text,\n",
    "            }\n",
    "            for s in segments\n",
    "        ]\n",
    "\n",
    "        return segments"
   ],
   "id": "d3ca9c90b82fa755"
  },
  {
   "metadata": {
    "id": "692121ab18b5f135",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "41f83829-5518-4ecf-b1fb-20691ab8d7fb"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 14min 11s, sys: 14.7 s, total: 14min 25s\n",
      "Wall time: 13min 48s\n"
     ]
    }
   ],
   "execution_count": null,
   "source": [
    "#14 minutes for a 1h10 video on T4\n",
    "%time transcript = speech_to_text(whisper_model, audio_path)\n"
   ],
   "id": "692121ab18b5f135"
  },
  {
   "cell_type": "code",
   "source": [
    "transcript[0:3]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WKTasl06iMyK",
    "outputId": "6878fad4-150c-4852-83c4-ea6075b72b21",
    "ExecuteTime": {
     "end_time": "2024-09-09T07:30:49.924302Z",
     "start_time": "2024-09-09T07:30:49.920603Z"
    }
   },
   "id": "WKTasl06iMyK",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 1.17, 'text': '[Music]'},\n",
       " {'start': 10.28, 'text': 'good afternoon everyone and welcome to'},\n",
       " {'start': 12.88, 'text': 'MIT sus1 191 my name is Alexander amini'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "2634bb12bad96f22",
    "ExecuteTime": {
     "end_time": "2024-09-09T07:31:11.976579Z",
     "start_time": "2024-09-09T07:31:11.966415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(f\"{DATA_DIR}/{video_id}_transcript.json\", \"w\") as f:\n",
    "        json.dump(transcript, f, indent=4)"
   ],
   "id": "2634bb12bad96f22",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "8b9e0979f4750865"
   },
   "cell_type": "markdown",
   "source": [
    "## 2) Structure transcript in paragraphs\n",
    "\n",
    "This stage improves the transcript's readability (using an LLM) by:\n",
    " \n",
    "- adding punctuation\n",
    "- removing verbal tics\n",
    "- and adding appropriate line breaks\n",
    "\n",
    "The addition of linebreaks allows to separate the transcript in paragraphs.\n"
   ],
   "id": "8b9e0979f4750865"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Concatenate text\n",
    "\n",
    "We first start by concatenating the text of the transcript in order to send it to the LLM in chunks.\n",
    "\n",
    "This removes the timestamp information, which will be added back later (with the help of TF-IDF, in stage 3 below)."
   ],
   "metadata": {
    "id": "G9jU4bzD-Pm_"
   },
   "id": "G9jU4bzD-Pm_"
  },
  {
   "cell_type": "code",
   "source": [
    "def get_transcript_as_text(transcript):\n",
    "    temp_list = [s['text'] for s in transcript]\n",
    "    transcript_as_text = ' '.join(temp_list)\n",
    "\n",
    "    return transcript_as_text\n",
    "\n",
    "transcript_as_text = get_transcript_as_text(transcript)\n",
    "\n",
    "print(\"Number of characters: \"+str(len(transcript_as_text))+\"\\n\")\n",
    "\n",
    "#print(\"First 1000 characters: \")\n",
    "transcript_as_text[0:1000]\n",
    "#transcript_as_text"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "5wDi7NYZ-Xnu",
    "outputId": "efabfcbf-3ce6-4226-c7f3-a15e235c3e07",
    "ExecuteTime": {
     "end_time": "2024-09-09T07:31:48.204678Z",
     "start_time": "2024-09-09T07:31:48.187389Z"
    }
   },
   "id": "5wDi7NYZ-Xnu",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 66632\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[Music] good afternoon everyone and welcome to MIT sus1 191 my name is Alexander amini and I'll be one of your instructors for the course this year along with Ava and together we're really excited to welcome you to this really incredible course this is a very fast-paced and very uh intense one week that we're about to go through together right so we're going to cover the foundations of a also very fast-paced moving field and a field that has been rapidly changing over the past eight years that we have taught this course at MIT now over the past decade in fact even before we started teaching this course Ai and deep learning has really been revolutionizing so many different advances and so many different areas of science meth mathematics physics and and so on and not that long ago we were having new types of we were having challenges and problems that we did not think were necessarily solvable in our lifetimes that AI is now actually solving uh Beyond human performance today and each yea\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Get LLM client\n",
    "\n",
    "Groq llama3-8b-8192 is faster and cheaper than OpenAI gpt-4o-mini, but is slightly less accurate.\n",
    "\n",
    "If using Groq, change chunk_size_format_transcript to 1500 for better results (otherwise part of the input may go missing)."
   ],
   "id": "3bfa66771a1b97fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T07:45:53.840316Z",
     "start_time": "2024-09-09T07:45:53.807164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Uncomment below to use Groq\n",
    "#llm_client_format_transcript = Groq(api_key=GROQ_API_KEY)\n",
    "#llm_model_format_transcript = 'llama3-8b-8192'\n",
    "#chunk_size_format_transcript = 1500\n",
    "\n",
    "# Comment below to use GPT-4o-mini\n",
    "llm_client_format_transcript = OpenAI(api_key=OPENAI_API_KEY)\n",
    "llm_model_format_transcript= \"gpt-4o-mini-2024-07-18\"\n",
    "chunk_size_format_transcript = 5000"
   ],
   "id": "5b92b24f5704513d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Price list for different LLMs (as of September 2024):",
   "id": "58f2552a23980150"
  },
  {
   "cell_type": "code",
   "source": [
    "price_token={'gpt-4o': {'input': 5/1000000, 'output': 15/1000000},\n",
    "             'gpt-4o-2024-08-06': {'input': 2.5/1000000, 'output': 10/1000000},\n",
    "             'gpt-4o-mini-2024-07-18': {'input': 0.15/1000000, 'output': 0.6/1000000},\n",
    "             'llama3-8b-8192' : {'input': 0.05 / 1000000, 'output': 0.08 / 1000000},\n",
    "             'llama3-70b-8192' : {'input': 0.59 / 1000000, 'output': 0.79 / 1000000},\n",
    "             'claude-3-5-sonnet-20240620': {'input': 3/1000000, 'output': 15/1000000},\n",
    "             'claude-3-haiku-20240307': {'input': 0.25/1000000, 'output': 1.25/1000000},\n",
    "             }"
   ],
   "metadata": {
    "id": "gBl4FhkDpyQi",
    "ExecuteTime": {
     "end_time": "2024-09-09T07:45:55.125138Z",
     "start_time": "2024-09-09T07:45:55.122874Z"
    }
   },
   "id": "gBl4FhkDpyQi",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Call LLM\n",
    "\n",
    "The call_llm function sends a prompt to the LLM and returns the response. It also calculates the price based on the number of tokens used."
   ],
   "id": "dbe320b7a247900c"
  },
  {
   "cell_type": "code",
   "source": [
    "def call_llm(client, model, system_prompt, prompt,\n",
    "             temperature=0, seed=42, response_format=None, max_tokens=4000):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        model=model, \n",
    "        temperature=temperature,\n",
    "        seed=seed,\n",
    "        response_format=response_format,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    nb_input_tokens = response.usage.prompt_tokens\n",
    "    nb_output_tokens = response.usage.completion_tokens\n",
    "    price = nb_input_tokens * price_token[model]['input'] + nb_output_tokens * price_token[model]['output']\n",
    "\n",
    "    print(f\"input tokens: {nb_input_tokens}; output tokens: {nb_output_tokens}, price: {price}\")\n",
    "\n",
    "    response_content=response.choices[0].message.content\n",
    "\n",
    "    return response_content, nb_input_tokens, nb_output_tokens, price\n"
   ],
   "metadata": {
    "id": "noAh3ZhhgnDy",
    "ExecuteTime": {
     "end_time": "2024-09-09T07:45:55.909695Z",
     "start_time": "2024-09-09T07:45:55.907006Z"
    }
   },
   "id": "noAh3ZhhgnDy",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The system prompt for the transcript formatting task is as follows:",
   "id": "ef4cf614a09e615c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T07:45:58.778638Z",
     "start_time": "2024-09-09T07:45:58.776557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt_transcript_to_paragraphs = f\"\"\"\n",
    "\n",
    "You are a helpful assistant.\n",
    "\n",
    "Your task is to improve the user input's readability: add punctuation if needed and remove verbal tics, and structure the text in paragraphs separated with '\\n\\n'.\n",
    "\n",
    "Keep the wording as faithful as possible to the original text. \n",
    "\n",
    "Put your answer within <answer></answer> tags.\n",
    "\n",
    "\"\"\""
   ],
   "id": "9edf2961f55f1b6b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Test the LLM on a chunk of the transcript."
   ],
   "id": "8d541a7ec69bcdde"
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "response_content, nb_input_tokens, nb_output_tokens, price = \\\n",
    "            call_llm(llm_client_format_transcript, llm_model_format_transcript,\n",
    "                     system_prompt_transcript_to_paragraphs, transcript_as_text[0:chunk_size_format_transcript],\n",
    "                     temperature=0, seed=42, response_format=None)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g-nat4pnoWPW",
    "outputId": "0d7c44c6-9ba4-4fcb-a70c-7bc26f0dc527",
    "ExecuteTime": {
     "end_time": "2024-09-09T07:46:08.341361Z",
     "start_time": "2024-09-09T07:45:59.908074Z"
    }
   },
   "id": "g-nat4pnoWPW",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tokens: 1007; output tokens: 905, price: 0.00069405\n",
      "CPU times: user 9.66 ms, sys: 12.4 ms, total: 22.1 ms\n",
      "Wall time: 8.43 s\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T07:46:08.346942Z",
     "start_time": "2024-09-09T07:46:08.344333Z"
    }
   },
   "cell_type": "code",
   "source": "print(response_content)\n",
   "id": "1b5a6cf314eef9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<answer>[Music] Good afternoon, everyone, and welcome to MIT's 6.S191. My name is Alexander Amini, and I'll be one of your instructors for the course this year, along with Ava. Together, we're really excited to welcome you to this incredible course.\n",
      "\n",
      "This is a very fast-paced and intense one week that we're about to go through together. We will cover the foundations of a rapidly evolving field that has been changing significantly over the past eight years since we began teaching this course at MIT. In fact, over the past decade, even before we started teaching this course, AI and deep learning have been revolutionizing many different areas of science, mathematics, physics, and more.\n",
      "\n",
      "Not long ago, we faced challenges and problems that we did not think were necessarily solvable in our lifetimes. However, AI is now solving these problems, often exceeding human performance. Each year that we teach this course, this lecture in particular is becoming harder to teach. For an introductory level course, this first lecture is supposed to cover the foundations. If you think about any other introductory course, like a 101 course in mathematics or biology, those first lectures don't change much over time. But we are in a rapidly changing field of AI and deep learning, where even these foundational lectures are evolving quickly.\n",
      "\n",
      "Let me give you an example of how we introduced this course only a few years ago. We welcomed everyone to MIT 6.S191, the official introductory course on deep learning taught here at MIT. Deep learning is revolutionizing many fields, from robotics to medicine and everything in between. In this course, you'll learn the fundamentals of this field and how to build incredible algorithms. In fact, the entire speech and video you just watched were not real; they were created using deep learning and artificial intelligence. In this class, you'll learn how it has been an honor to speak with you today, and I hope you enjoy the course.\n",
      "\n",
      "The really surprising thing about that video, when we first created it, was how viral it went a few years ago. Within just a couple of months of us teaching this course, that video received over a million views. People were shocked by a few things, but the main one was the realism of AI in generating content that looks and sounds extremely hyper-realistic. When we created this video for the class, it cost us about $10,000 in compute to generate just about a minute-long video. If you think about it, that's extremely expensive for computing something like that. \n",
      "\n",
      "Today, many of you might not even be impressed by the technology because you see all the amazing things that AI and deep learning are producing now. Fast forward to today, the progress in deep learning has been remarkable. People were making all kinds of exciting remarks about it when it first came out a few years ago, but now this is common technology. AI is now doing much more powerful things than that fun little introductory video.\n",
      "\n",
      "So, where are we now, about four years later? AI is generating content with deep learning being so commoditized. Deep learning is at our fingertips now, available online and on our smartphones. In fact, we can use deep learning to generate hyper-realistic pieces of media and content entirely from English language prompts, without even needing to code anymore. \n",
      "\n",
      "Before, we had to train these models and code them to create that one-minute-long video. Today, we have models that can do that for us end-to-end, directly from English language prompts. We can ask these models to create something that the world has never seen before, like a photo of an astronaut riding a horse. These models can imagine those pieces of content entirely from scratch.\n",
      "\n",
      "My personal favorite is how we can now ask these deep learning models to create new types of software. For example, we can ask them to write a piece of TensorFlow code to train a neural network. We are asking a neural network to write TensorFlow code to train another neural network, and our model can produce examples of functional and usable pieces of code that satisfy this English prompt, while also walking through each part of the code independently. \n",
      "\n",
      "This is not just about producing code; it's also about educating and teaching the user on what each part of these code blocks is doing. You can see examples of this, and what I'm trying to show you with all of this is how far deep learning has come, even in just a couple of years since we started teaching this course. \n",
      "\n",
      "Going back even further... </answer>\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Process the whole transcript\n",
    "\n",
    "Split the transcript in chunks and process iteratively."
   ],
   "id": "1c320e9c807f5728"
  },
  {
   "cell_type": "code",
   "source": [
    "def transcript_to_paragraphs(transcript, llm_client, llm_model, chunk_size=5000, progress=None):\n",
    "\n",
    "    transcript_as_text = ' '.join([s['text'] for s in transcript])\n",
    "\n",
    "    paragraphs = []\n",
    "    last_paragraph = \"\"\n",
    "\n",
    "    total_nb_input_tokens, total_nb_output_tokens, total_price = 0, 0, 0\n",
    "    \n",
    "    nb_chunks = int(len(transcript_as_text) / chunk_size) + 1\n",
    "    progress_i = 0\n",
    "    print(f\"Number of chunks: {nb_chunks}\")\n",
    "\n",
    "    #for i in range(0, 10000, chunk_size): \n",
    "    for i in range(0, len(transcript_as_text), chunk_size):\n",
    "        \n",
    "        print (\"i is: \"+str(i))\n",
    "        \n",
    "        chunk = last_paragraph + \" \" + transcript_as_text[i:i + chunk_size]\n",
    "        \n",
    "        if progress is not None:\n",
    "            progress_i += 1\n",
    "            progress(progress_i/nb_chunks, desc=\"Processing\")\n",
    "        \n",
    "        found_edited_transcript = False\n",
    "    \n",
    "        while not found_edited_transcript:\n",
    "\n",
    "            response_content, nb_input_tokens, nb_output_tokens, price = \\\n",
    "                call_llm(llm_client, llm_model, \n",
    "                     system_prompt = system_prompt_transcript_to_paragraphs, prompt = chunk,\n",
    "                     temperature=0.2, seed=42, response_format=None)\n",
    "        \n",
    "            # Sometimes the model 'forgets' to close the <answer> tag\n",
    "            if not \"</answer>\" in response_content:\n",
    "                response_content += \"</answer>\"\n",
    "                \n",
    "            # Extract content from <edited_transcript> tags\n",
    "            pattern = re.compile(r'<answer>(.*?)</answer>', re.DOTALL)\n",
    "            response_content_edited =  pattern.findall(response_content)\n",
    "            \n",
    "            if len(response_content_edited) > 0:\n",
    "                found_edited_transcript = True\n",
    "                response_content_edited = response_content_edited[0]\n",
    "            \n",
    "            else:\n",
    "                print(\"No edited transcript found. Trying again.\")\n",
    "                print(response_content[0:100])\n",
    "                print(response_content[-100:])\n",
    "                \n",
    "\n",
    "        total_nb_input_tokens += nb_input_tokens\n",
    "        total_nb_output_tokens += nb_output_tokens\n",
    "        total_price += price\n",
    "    \n",
    "        paragraphs_chunk = response_content_edited.strip().split('\\n\\n')\n",
    "\n",
    "        print('Found paragraphs:', len(paragraphs_chunk))\n",
    "        last_paragraph = paragraphs_chunk[-1]\n",
    "\n",
    "        paragraphs += paragraphs_chunk[:-1]\n",
    "\n",
    "    paragraphs += [last_paragraph]\n",
    "\n",
    "    paragraphs_dict = [{'paragraph_number': i, 'paragraph_text': paragraph} for i, paragraph in enumerate(paragraphs)]\n",
    "\n",
    "    return paragraphs_dict, total_nb_input_tokens, total_nb_output_tokens, total_price\n"
   ],
   "metadata": {
    "id": "xDKg5f2egBan",
    "ExecuteTime": {
     "end_time": "2024-09-09T08:04:30.248112Z",
     "start_time": "2024-09-09T08:04:30.237083Z"
    }
   },
   "id": "xDKg5f2egBan",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "id": "14c2033d59021116",
    "outputId": "8bec6958-73c3-4663-ac9a-adda8ee99690",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-09-09T08:06:43.452617Z",
     "start_time": "2024-09-09T08:04:31.601236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "paragraphs, nb_input_tokens, nb_output_tokens, price = transcript_to_paragraphs(transcript, llm_client_format_transcript, llm_model_format_transcript, chunk_size=chunk_size_format_transcript)"
   ],
   "id": "14c2033d59021116",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 14\n",
      "i is: 0\n",
      "input tokens: 1007; output tokens: 842, price: 0.00065625\n",
      "Found paragraphs: 10\n",
      "i is: 5000\n",
      "input tokens: 1033; output tokens: 986, price: 0.0007465499999999999\n",
      "Found paragraphs: 16\n",
      "i is: 10000\n",
      "input tokens: 1083; output tokens: 945, price: 0.00072945\n",
      "Found paragraphs: 12\n",
      "i is: 15000\n",
      "input tokens: 1026; output tokens: 885, price: 0.0006849\n",
      "Found paragraphs: 13\n",
      "i is: 20000\n",
      "input tokens: 1094; output tokens: 972, price: 0.0007473\n",
      "Found paragraphs: 11\n",
      "i is: 25000\n",
      "input tokens: 1151; output tokens: 1128, price: 0.00084945\n",
      "Found paragraphs: 12\n",
      "i is: 30000\n",
      "input tokens: 1133; output tokens: 1128, price: 0.00084675\n",
      "Found paragraphs: 14\n",
      "i is: 35000\n",
      "input tokens: 1135; output tokens: 1093, price: 0.00082605\n",
      "Found paragraphs: 19\n",
      "i is: 40000\n",
      "input tokens: 1082; output tokens: 1004, price: 0.0007647\n",
      "Found paragraphs: 15\n",
      "i is: 45000\n",
      "input tokens: 1062; output tokens: 924, price: 0.0007137\n",
      "Found paragraphs: 12\n",
      "i is: 50000\n",
      "input tokens: 1054; output tokens: 926, price: 0.0007137\n",
      "Found paragraphs: 15\n",
      "i is: 55000\n",
      "input tokens: 1068; output tokens: 998, price: 0.000759\n",
      "Found paragraphs: 13\n",
      "i is: 60000\n",
      "input tokens: 1059; output tokens: 840, price: 0.00066285\n",
      "Found paragraphs: 9\n",
      "i is: 65000\n",
      "input tokens: 451; output tokens: 381, price: 0.00029624999999999996\n",
      "Found paragraphs: 5\n",
      "CPU times: user 147 ms, sys: 45 ms, total: 192 ms\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:12:21.055059Z",
     "start_time": "2024-09-09T08:12:21.049225Z"
    }
   },
   "cell_type": "code",
   "source": "len(paragraphs)",
   "id": "95624586f1a934a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check result with the first paragraphs",
   "id": "936699fe7d755bce"
  },
  {
   "metadata": {
    "id": "bf5640596a00415e",
    "outputId": "7cdcf124-f964-4868-f60b-3cb1ee16112d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-09-09T08:12:44.768816Z",
     "start_time": "2024-09-09T08:12:44.762502Z"
    }
   },
   "cell_type": "code",
   "source": "paragraphs[0:3]",
   "id": "bf5640596a00415e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'paragraph_number': 0,\n",
       "  'paragraph_text': \"[Music] Good afternoon, everyone, and welcome to MIT's 6.S191. My name is Alexander Amini, and I'll be one of your instructors for the course this year, along with Ava. Together, we're really excited to welcome you to this incredible course.\"},\n",
       " {'paragraph_number': 1,\n",
       "  'paragraph_text': \"This is a very fast-paced and intense one-week experience that we're about to go through together. We will cover the foundations of a rapidly evolving field that has been changing significantly over the past eight years that we have taught this course at MIT. In fact, over the past decade, even before we started teaching this course, AI and deep learning have been revolutionizing many different areas of science, mathematics, physics, and more.\"},\n",
       " {'paragraph_number': 2,\n",
       "  'paragraph_text': \"Not long ago, we faced challenges and problems that we did not think were necessarily solvable in our lifetimes. Yet, AI is now solving these problems, often surpassing human performance. Each year that we teach this course, this particular lecture is getting harder and harder to deliver. For an introductory level course, this first lecture is supposed to cover the foundations. If you think about any other introductory course, like a 101 course in mathematics or biology, those first lectures don't change much over time. However, we are in a rapidly changing field of AI and deep learning, where even these foundational lectures are evolving quickly.\"}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the paragraphs in a JSON file",
   "id": "a3611c3db8b7cb6"
  },
  {
   "cell_type": "code",
   "source": [
    "with open(f\"{DATA_DIR}/{video_id}_paragraphs.json\", \"w\") as f:\n",
    "        json.dump(paragraphs, f, indent=4)"
   ],
   "metadata": {
    "id": "JDKP4rTDhzET",
    "ExecuteTime": {
     "end_time": "2024-09-09T08:12:50.243981Z",
     "start_time": "2024-09-09T08:12:50.238980Z"
    }
   },
   "id": "JDKP4rTDhzET",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "id": "e6f2e71c0a57eaa7"
   },
   "cell_type": "markdown",
   "source": [
    "## 3) Infer paragraph timestamps \n",
    "\n",
    "Let us now add back the timestamps to the paragraphs, using TF-IDF to match the paragraphs to the transcript segments.\n",
    "\n",
    "The transform_text_segments function takes a list of text segments and combines them into a list of segments, each containing a specified number of words. \n",
    "\n",
    "For example, given the five following text segments from the transcript:\n",
    "\n",
    "```\n",
    "transcript[0:5]\n",
    "[{'start': 1.17, 'text': '[Music]'},\n",
    " {'start': 10.28, 'text': 'good afternoon everyone and welcome to'},\n",
    " {'start': 12.88, 'text': 'MIT sus1 191 my name is Alexander amini'},\n",
    " {'start': 16.84, 'text': \"and I'll be one of your instructors for\"},\n",
    " {'start': 18.32, 'text': 'the course this year along with Ava and'}]\n",
    "```\n",
    "\n",
    "Call the transform_text_segments function with a num_words parameter of 10 would combine these segments into the following segments:\n",
    "\n",
    "```\n",
    "['[Music] good afternoon everyone and welcome to MIT sus1 191',\n",
    " 'good afternoon everyone and welcome to MIT sus1 191 my',\n",
    " \"MIT sus1 191 my name is Alexander amini and I'll\",\n",
    " \"and I'll be one of your instructors for the course\",\n",
    " 'the course this year along with Ava and']\n",
    "```\n",
    "\n",
    "Each segment contains a maximum of 10 words, and the last segment contains the remaining words from the original segments. This will be useful for the next step, where we will match the paragraphs to the transcript segments using TF-IDF."
   ],
   "id": "e6f2e71c0a57eaa7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:28:24.984444Z",
     "start_time": "2024-09-09T08:28:24.972379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transform_text_segments(text_segments, num_words=50):\n",
    "    # Initialize variables\n",
    "    transformed_segments = []\n",
    "    current_index = 0\n",
    "    num_segments = len(text_segments)\n",
    "\n",
    "    for i in range(num_segments):\n",
    "\n",
    "        current_index = i\n",
    "\n",
    "        # Get the current segment's starting timestamp and text\n",
    "        current_segment = text_segments[current_index]\n",
    "        current_text = current_segment['text']\n",
    "\n",
    "        # Initialize a list to hold the combined text\n",
    "        combined_text = \" \".join(current_text.split()[:num_words])\n",
    "        number_words_collected = len(current_text.split())\n",
    "\n",
    "        # Collect words from subsequent segments\n",
    "        while number_words_collected < num_words and (current_index + 1) < num_segments:\n",
    "            current_index += 1\n",
    "            next_segment = text_segments[current_index]\n",
    "            next_text = next_segment['text']\n",
    "            next_words = next_text.split()\n",
    "\n",
    "            # Append words from the next segment\n",
    "            if number_words_collected + len(next_words) <= num_words:\n",
    "                combined_text += ' ' + next_text\n",
    "                number_words_collected += len(next_words)\n",
    "            else:\n",
    "                # Only append enough words to reach the num_words limit\n",
    "                words_needed = num_words - number_words_collected\n",
    "                combined_text += ' ' + ' '.join(next_words[:words_needed])\n",
    "                number_words_collected = num_words\n",
    "\n",
    "        # Append the combined segment to the result\n",
    "        transformed_segments.append(combined_text)\n",
    "\n",
    "    return transformed_segments\n",
    "\n"
   ],
   "id": "e8d7831f7697231f",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:28:27.621772Z",
     "start_time": "2024-09-09T08:28:27.618249Z"
    }
   },
   "cell_type": "code",
   "source": "transcript[0:5]",
   "id": "c9d95b0a991cd408",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 1.17, 'text': '[Music]'},\n",
       " {'start': 10.28, 'text': 'good afternoon everyone and welcome to'},\n",
       " {'start': 12.88, 'text': 'MIT sus1 191 my name is Alexander amini'},\n",
       " {'start': 16.84, 'text': \"and I'll be one of your instructors for\"},\n",
       " {'start': 18.32, 'text': 'the course this year along with Ava and'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:28:38.826156Z",
     "start_time": "2024-09-09T08:28:38.822873Z"
    }
   },
   "cell_type": "code",
   "source": "transform_text_segments(transcript[0:5], num_words=10)",
   "id": "31f646d194080d21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Music] good afternoon everyone and welcome to MIT sus1 191',\n",
       " 'good afternoon everyone and welcome to MIT sus1 191 my',\n",
       " \"MIT sus1 191 my name is Alexander amini and I'll\",\n",
       " \"and I'll be one of your instructors for the course\",\n",
       " 'the course this year along with Ava and']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The add_timestamps_to_paragraphs function takes the transcript and the paragraphs and add back the timestamps to the paragraphs. It uses TF-IDF to find the most similar segment in the transcript for each paragraph.",
   "id": "b2da01e1fec34d2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:28:50.522998Z",
     "start_time": "2024-09-09T08:28:50.518063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_timestamps_to_paragraphs(transcript, paragraphs, num_words=50):\n",
    "    list_indices = []\n",
    "    \n",
    "    transcript_num_words = transform_text_segments(transcript, num_words=num_words)\n",
    "\n",
    "    paragraphs_start_text = [{\"start\": p['paragraph_number'], \"text\": p['paragraph_text']} for p in paragraphs]\n",
    "    paragraphs_num_words = transform_text_segments(paragraphs_start_text, num_words=num_words)\n",
    "    \n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer().fit_transform(transcript_num_words + paragraphs_num_words)\n",
    "    # Get the TF-IDF vectors for the transcript and the excerpt\n",
    "    vectors = vectorizer.toarray()\n",
    "    \n",
    "    for i in range(len(paragraphs_num_words)):\n",
    "        \n",
    "        # Extract the TF-IDF vector for the paragraph\n",
    "        paragraph_vector = vectors[len(transcript_num_words) + i]\n",
    "\n",
    "        # Calculate the cosine similarity between the paragraph vector and each transcript chunk\n",
    "        similarities = cosine_similarity(vectors[:len(transcript_num_words)], paragraph_vector.reshape(1, -1))\n",
    "        # Find the index of the most similar chunk\n",
    "        best_match_index = int(np.argmax(similarities))\n",
    "\n",
    "        list_indices.append(best_match_index)\n",
    "\n",
    "        paragraphs[i]['matched_index'] = best_match_index\n",
    "        paragraphs[i]['matched_text'] = transcript[best_match_index]['text']\n",
    "        paragraphs[i]['start_time'] = int(transcript[best_match_index]['start'])-2\n",
    "        if paragraphs[i]['start_time'] < 0:\n",
    "            paragraphs[i]['start_time'] = 0\n",
    "\n",
    "\n",
    "    return paragraphs"
   ],
   "id": "1868a850893fd82a",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:28:53.654419Z",
     "start_time": "2024-09-09T08:28:51.640337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "paragraphs = add_timestamps_to_paragraphs(transcript, paragraphs, num_words=50)"
   ],
   "id": "1a59469cc79aadb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.37 s, sys: 4.32 s, total: 11.7 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example of the first paragraphs where the timestamps have been added back (start_time, in seconds):",
   "id": "c8669d86dce7e72c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:28:56.580721Z",
     "start_time": "2024-09-09T08:28:56.578043Z"
    }
   },
   "cell_type": "code",
   "source": "paragraphs[0:5]",
   "id": "4ded164aba383ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'paragraph_number': 0,\n",
       "  'paragraph_text': \"[Music] Good afternoon, everyone, and welcome to MIT's 6.S191. My name is Alexander Amini, and I'll be one of your instructors for the course this year, along with Ava. Together, we're really excited to welcome you to this incredible course.\",\n",
       "  'matched_index': 0,\n",
       "  'matched_text': '[Music]',\n",
       "  'start_time': 0},\n",
       " {'paragraph_number': 1,\n",
       "  'paragraph_text': \"This is a very fast-paced and intense one-week experience that we're about to go through together. We will cover the foundations of a rapidly evolving field that has been changing significantly over the past eight years that we have taught this course at MIT. In fact, over the past decade, even before we started teaching this course, AI and deep learning have been revolutionizing many different areas of science, mathematics, physics, and more.\",\n",
       "  'matched_index': 8,\n",
       "  'matched_text': \"intense one week that we're about to go\",\n",
       "  'start_time': 27},\n",
       " {'paragraph_number': 2,\n",
       "  'paragraph_text': \"Not long ago, we faced challenges and problems that we did not think were necessarily solvable in our lifetimes. Yet, AI is now solving these problems, often surpassing human performance. Each year that we teach this course, this particular lecture is getting harder and harder to deliver. For an introductory level course, this first lecture is supposed to cover the foundations. If you think about any other introductory course, like a 101 course in mathematics or biology, those first lectures don't change much over time. However, we are in a rapidly changing field of AI and deep learning, where even these foundational lectures are evolving quickly.\",\n",
       "  'matched_index': 22,\n",
       "  'matched_text': 'having challenges and problems that we',\n",
       "  'start_time': 65},\n",
       " {'paragraph_number': 3,\n",
       "  'paragraph_text': \"Let me give you an example of how we introduced this course only a few years ago. We welcomed everyone to MIT's 6.S191, the official introductory course on deep learning taught here at MIT. Deep learning is revolutionizing many fields, from robotics to medicine and everything in between. In this course, you'll learn the fundamentals of this field and how to build incredible algorithms. In fact, the entire speech and video you just watched were not real; they were created using deep learning and artificial intelligence. In this class, you'll learn how this technology works.\",\n",
       "  'matched_index': 40,\n",
       "  'matched_text': 'me give you an example of how we',\n",
       "  'start_time': 113},\n",
       " {'paragraph_number': 4,\n",
       "  'paragraph_text': \"The surprising thing about that video, when we first created it, was how viral it went a few years ago. Within just a couple of months of teaching this course, that video garnered over a million views. People were shocked by a few things, but the main one was the realism of AI in generating content that looks and sounds hyper-realistic. When we created that video, it took us about $10,000 in compute to generate just a minute-long video. If you think about it, that's extremely expensive for computing something like that. \",\n",
       "  'matched_index': 62,\n",
       "  'matched_text': 'just in a couple months of us teaching',\n",
       "  'start_time': 185}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the paragraphs with timestamps in a JSON file",
   "id": "4a23f5156d70dcb0"
  },
  {
   "metadata": {
    "id": "731c882780906b9b",
    "ExecuteTime": {
     "end_time": "2024-09-09T08:29:06.386069Z",
     "start_time": "2024-09-09T08:29:06.381181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(f\"{DATA_DIR}/{video_id}_paragraphs.json\", \"w\") as f:\n",
    "        json.dump(paragraphs, f, indent=4)"
   ],
   "id": "731c882780906b9b",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4) Generate table of content\n",
    "\n",
    "The table of content is found by grouping consecutive paragraphs into chapters and identifying meaningful chapter titles.\n"
   ],
   "id": "a5f60c0c91f79a54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:33:56.248597Z",
     "start_time": "2024-09-09T08:33:56.241091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "paragraphs_number_text = [{'paragraph_number': p['paragraph_number'], 'paragraph_text': p['paragraph_text']} for p in paragraphs]\n",
    "paragraphs_json_dump = json.dumps(paragraphs_number_text)\n",
    "\n",
    "paragraphs_json_dump[0:1000]"
   ],
   "id": "4d9d0d40a4fcd8b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"paragraph_number\": 0, \"paragraph_text\": \"[Music] Good afternoon, everyone, and welcome to MIT\\'s 6.S191. My name is Alexander Amini, and I\\'ll be one of your instructors for the course this year, along with Ava. Together, we\\'re really excited to welcome you to this incredible course.\"}, {\"paragraph_number\": 1, \"paragraph_text\": \"This is a very fast-paced and intense one-week experience that we\\'re about to go through together. We will cover the foundations of a rapidly evolving field that has been changing significantly over the past eight years that we have taught this course at MIT. In fact, over the past decade, even before we started teaching this course, AI and deep learning have been revolutionizing many different areas of science, mathematics, physics, and more.\"}, {\"paragraph_number\": 2, \"paragraph_text\": \"Not long ago, we faced challenges and problems that we did not think were necessarily solvable in our lifetimes. Yet, AI is now solving these problems, often surpassing human'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:34:00.319622Z",
     "start_time": "2024-09-09T08:34:00.317156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt_paragraphs_to_toc = \"\"\"\n",
    "\n",
    "\tYou are a helpful assistant.\n",
    "\n",
    "\tYou are given a transcript of a course in JSON format as a list of paragraphs, each containing 'paragraph_number' and 'paragraph_text' keys.\n",
    "\n",
    "\tYour task is to group consecutive paragraphs in chapters for the course and identify meaningful chapter titles.\n",
    "\n",
    "\tHere are the steps to follow:\n",
    "\n",
    "1. Read the transcript carefully to understand its general structure and the main topics covered.\n",
    "2. Look for clues that a new chapter is about to start. This could be a change of topic, a change of time or setting, the introduction of new themes or topics, or the speaker's explicit mention of a new part.\n",
    "3. For each chapter, keep track of the paragraph number that starts the chapter and identify a meaningful chapter title.\n",
    "4. Chapters should ideally be equally spaced throughout the transcript, and discuss a specific topic.\n",
    "\n",
    "\tFormat your result in JSON, with a list dictionaries for chapters, with 'start_paragraph_number':integer and 'title':string as key:value.\n",
    "\t\n",
    "\tExample: \n",
    "    {\"chapters\": \n",
    "        [{\"start_paragraph_number\": 0, \"title\": \"Introduction\"}, \n",
    "         {\"start_paragraph_number\": 10, \"title\": \"Chapter 1\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\"\"\""
   ],
   "id": "63acab68339a149e",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We use GPT-4o-mini for this task, as it is more cost-effective than OpenAI's GPT-4o and generally provides good results.",
   "id": "b9e7beefd3526588"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:40:39.720280Z",
     "start_time": "2024-09-09T08:40:39.684285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_client_get_toc = OpenAI(api_key=OPENAI_API_KEY)\n",
    "llm_model_get_toc= \"gpt-4o-mini-2024-07-18\"\n",
    "#llm_model_get_toc= \"gpt-4o-2024-08-06\"\n",
    "chunk_size_toc = 30"
   ],
   "id": "702b0fde3885304c",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:40:42.221228Z",
     "start_time": "2024-09-09T08:40:40.926377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "paragraphs_number_text = [{'paragraph_number': p['paragraph_number'], 'paragraph_text': p['paragraph_text']} for p in paragraphs]\n",
    "chunk_json_dump = json.dumps(paragraphs_number_text[0:chunk_size_toc])\n",
    "\n",
    "response, _, _, _ = call_llm(llm_client_get_toc, llm_model_get_toc, \\\n",
    "                    system_prompt_paragraphs_to_toc, chunk_json_dump, \\\n",
    "                    temperature=0, seed=42, response_format={\"type\": \"json_object\"})\n"
   ],
   "id": "686fa50474649618",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tokens: 2897; output tokens: 107, price: 0.00049875\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:40:44.171738Z",
     "start_time": "2024-09-09T08:40:44.169333Z"
    }
   },
   "cell_type": "code",
   "source": "print(response)",
   "id": "376c3f9b23a93135",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"chapters\": [\n",
      "    {\n",
      "      \"start_paragraph_number\": 0,\n",
      "      \"title\": \"Introduction to the Course\"\n",
      "    },\n",
      "    {\n",
      "      \"start_paragraph_number\": 10,\n",
      "      \"title\": \"Foundations of Deep Learning\"\n",
      "    },\n",
      "    {\n",
      "      \"start_paragraph_number\": 20,\n",
      "      \"title\": \"Course Structure and Labs\"\n",
      "    },\n",
      "    {\n",
      "      \"start_paragraph_number\": 26,\n",
      "      \"title\": \"Project and Resources Overview\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We generate the TOC sequentially on chunks of paragraphs as it generally provides better results.",
   "id": "b3af76ab074cc21a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:52:46.386988Z",
     "start_time": "2024-09-09T08:52:46.379577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def paragraphs_to_toc(paragraphs, llm_client, llm_model, chunk_size=100):\n",
    "\n",
    "    chapters = []\n",
    "    number_last_chapter = 0\n",
    "\n",
    "    total_nb_input_tokens, total_nb_output_tokens, total_price = 0, 0, 0\n",
    "\n",
    "    while number_last_chapter < len(paragraphs):\n",
    "\n",
    "        print(number_last_chapter)\n",
    "\n",
    "        chunk = paragraphs[number_last_chapter:(number_last_chapter + chunk_size)]\n",
    "        chunk = [{'paragraph_number': p['paragraph_number'], 'paragraph_text': p['paragraph_text']} for p in chunk]\n",
    "\n",
    "        chunk_json_dump = json.dumps(chunk)\n",
    "\n",
    "        content, nb_input_tokens, nb_output_tokens, price = call_llm(\\\n",
    "                llm_client, llm_model, \\\n",
    "                system_prompt_paragraphs_to_toc, chunk_json_dump, \\\n",
    "                temperature=0, seed=42, response_format={\"type\": \"json_object\"})\n",
    "\n",
    "        total_nb_input_tokens += nb_input_tokens\n",
    "        total_nb_output_tokens += nb_output_tokens\n",
    "        \n",
    "        chapters_chunk = json.loads(content)['chapters']\n",
    "        \n",
    "        if number_last_chapter == chapters_chunk[-1]['start_paragraph_number']:\n",
    "            break\n",
    "\n",
    "        chapters += chapters_chunk[:-1]\n",
    "        \n",
    "        number_last_chapter = chapters_chunk[-1]['start_paragraph_number']\n",
    "        if number_last_chapter >= len(paragraphs)-5:\n",
    "            break\n",
    "        \n",
    "    total_price = (total_nb_input_tokens * price_token[llm_model]['input'] + \n",
    "                   total_nb_output_tokens * price_token[llm_model]['output'])\n",
    "    \n",
    "    chapters += [chapters_chunk[-1]]\n",
    "\n",
    "    return chapters, total_nb_input_tokens, total_nb_output_tokens, total_price"
   ],
   "id": "7baa1cadb3bbdad7",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:53:09.939726Z",
     "start_time": "2024-09-09T08:53:00.837690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "table_of_content, total_nb_input_tokens, total_nb_output_tokens, total_price = \\\n",
    "    paragraphs_to_toc(paragraphs, llm_client_get_toc, llm_model_get_toc, chunk_size=chunk_size_toc)"
   ],
   "id": "193dd5276bbf6de6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "input tokens: 2897; output tokens: 107, price: 0.00049875\n",
      "26\n",
      "input tokens: 3061; output tokens: 157, price: 0.00055335\n",
      "53\n",
      "input tokens: 3202; output tokens: 95, price: 0.0005373\n",
      "73\n",
      "input tokens: 2759; output tokens: 132, price: 0.00049305\n",
      "99\n",
      "input tokens: 2827; output tokens: 91, price: 0.00047864999999999995\n",
      "125\n",
      "input tokens: 2969; output tokens: 118, price: 0.0005161499999999999\n",
      "149\n",
      "input tokens: 1690; output tokens: 90, price: 0.0003075\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:53:11.803987Z",
     "start_time": "2024-09-09T08:53:11.800285Z"
    }
   },
   "cell_type": "code",
   "source": "table_of_content",
   "id": "15649ecb2537f6ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_paragraph_number': 0, 'title': 'Introduction to the Course'},\n",
       " {'start_paragraph_number': 10, 'title': 'Foundations of Deep Learning'},\n",
       " {'start_paragraph_number': 20, 'title': 'Course Structure and Labs'},\n",
       " {'start_paragraph_number': 26, 'title': 'Course Overview and Resources'},\n",
       " {'start_paragraph_number': 29, 'title': 'Introduction to Deep Learning'},\n",
       " {'start_paragraph_number': 38, 'title': 'Understanding Perceptrons'},\n",
       " {'start_paragraph_number': 45,\n",
       "  'title': 'Activation Functions in Neural Networks'},\n",
       " {'start_paragraph_number': 50, 'title': 'Importance of Nonlinearities'},\n",
       " {'start_paragraph_number': 53,\n",
       "  'title': 'Understanding Neural Networks: Basics and Components'},\n",
       " {'start_paragraph_number': 62,\n",
       "  'title': 'Building Neural Networks: From Perceptrons to Layers'},\n",
       " {'start_paragraph_number': 73, 'title': 'Introduction to Neural Networks'},\n",
       " {'start_paragraph_number': 81, 'title': 'Building a Deep Neural Network'},\n",
       " {'start_paragraph_number': 84,\n",
       "  'title': 'Applying Neural Networks to Real Problems'},\n",
       " {'start_paragraph_number': 91, 'title': 'Training Neural Networks'},\n",
       " {'start_paragraph_number': 99,\n",
       "  'title': 'Introduction to Binary Classification and Loss Functions'},\n",
       " {'start_paragraph_number': 115,\n",
       "  'title': 'Gradient Descent and Backpropagation'},\n",
       " {'start_paragraph_number': 125,\n",
       "  'title': 'Understanding Neural Network Loss Landscapes'},\n",
       " {'start_paragraph_number': 139,\n",
       "  'title': 'Optimizers and Learning Rates in Practice'},\n",
       " {'start_paragraph_number': 141,\n",
       "  'title': 'Batching Data for Efficient Training'},\n",
       " {'start_paragraph_number': 149,\n",
       "  'title': 'Understanding Overfitting and Underfitting'},\n",
       " {'start_paragraph_number': 153,\n",
       "  'title': 'Regularization Techniques in Neural Networks'},\n",
       " {'start_paragraph_number': 160,\n",
       "  'title': 'Summary and Transition to Next Lecture'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:53:21.102193Z",
     "start_time": "2024-09-09T08:53:21.099610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(f\"{DATA_DIR}/{video_id}_toc.json\", \"w\") as f:\n",
    "        json.dump(table_of_content, f, indent=4)"
   ],
   "id": "3f986e192097041d",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "id": "d55415a36ca7ca84"
   },
   "cell_type": "markdown",
   "source": [
    "## 5) Output structured chapter\n",
    "\n",
    "This last stage combines the paragraphs and the table of content to create a structured JSON with chapters."
   ],
   "id": "d55415a36ca7ca84"
  },
  {
   "cell_type": "code",
   "source": [
    "def get_chapters(paragraphs, table_of_content):\n",
    "\n",
    "    chapters = []\n",
    "\n",
    "    for i in range(len(table_of_content)):\n",
    "\n",
    "\n",
    "        if i < len(table_of_content) - 1:\n",
    "\n",
    "            chapter = {'num_chapter': i,\n",
    "                       'title': table_of_content[i]['title'],\n",
    "                       'start_paragraph_number': table_of_content[i]['start_paragraph_number'],\n",
    "                       'end_paragraph_number': table_of_content[i + 1]['start_paragraph_number'],\n",
    "                       'start_time': paragraphs[table_of_content[i]['start_paragraph_number']]['start_time'],\n",
    "                       'end_time': paragraphs[table_of_content[i + 1]['start_paragraph_number']]['start_time'],\n",
    "                      }\n",
    "\n",
    "        else:\n",
    "            chapter = {'num_chapter': i,\n",
    "                       'title': table_of_content[i]['title'],\n",
    "                       'start_paragraph_number': table_of_content[i]['start_paragraph_number'],\n",
    "                       'end_paragraph_number': len(paragraphs),\n",
    "                       'start_time': paragraphs[table_of_content[i]['start_paragraph_number']]['start_time'],\n",
    "                       'end_time': paragraphs[-1]['start_time'],\n",
    "                      }\n",
    "\n",
    "        paragraphs_chapter = [paragraphs[j]['paragraph_text'] for j in\n",
    "                                range(chapter['start_paragraph_number'], chapter['end_paragraph_number'])]\n",
    "\n",
    "        paragraph_timestamps_chapter = [paragraphs[j]['start_time'] for j in\n",
    "                                          range(chapter['start_paragraph_number'], chapter['end_paragraph_number'])]\n",
    "\n",
    "        chapter['paragraphs'] = paragraphs_chapter\n",
    "        chapter['paragraph_timestamps'] = paragraph_timestamps_chapter\n",
    "\n",
    "        chapters.append(chapter)\n",
    "\n",
    "    return chapters"
   ],
   "metadata": {
    "id": "Es_UUTejvAhe",
    "ExecuteTime": {
     "end_time": "2024-09-09T08:54:14.381989Z",
     "start_time": "2024-09-09T08:54:14.357164Z"
    }
   },
   "id": "Es_UUTejvAhe",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "id": "feec2cdf35f1dbf8",
    "ExecuteTime": {
     "end_time": "2024-09-09T08:54:15.099379Z",
     "start_time": "2024-09-09T08:54:15.094178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chapters = get_chapters(paragraphs, table_of_content)\n"
   ],
   "id": "feec2cdf35f1dbf8",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "id": "6181283b929db001",
    "ExecuteTime": {
     "end_time": "2024-09-09T08:54:16.084636Z",
     "start_time": "2024-09-09T08:54:16.080166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(f\"{DATA_DIR}/{video_id}.json\", \"w\") as f:\n",
    "        json.dump(chapters, f, indent=4)"
   ],
   "id": "6181283b929db001",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:54:23.031331Z",
     "start_time": "2024-09-09T08:54:23.028358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_seconds_to_hms(seconds):\n",
    "    # Calculate hours, minutes, and remaining seconds\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    remaining_seconds = seconds % 60\n",
    "\n",
    "    # Format the result as HH:MM:SS\n",
    "    return f\"{hours:02}:{minutes:02}:{remaining_seconds:02}\""
   ],
   "id": "64af9ffed386c69b",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T08:54:23.831452Z",
     "start_time": "2024-09-09T08:54:23.829523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chapter in chapters:\n",
    "    print(convert_seconds_to_hms(chapter['start_time'])+\" : \"+chapter['title'])"
   ],
   "id": "5df8c8b4959d4d6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00:00 : Introduction to the Course\n",
      "00:06:05 : Foundations of Deep Learning\n",
      "00:09:37 : Course Structure and Labs\n",
      "00:12:07 : Course Overview and Resources\n",
      "00:13:36 : Introduction to Deep Learning\n",
      "00:17:24 : Understanding Perceptrons\n",
      "00:20:40 : Activation Functions in Neural Networks\n",
      "00:22:59 : Importance of Nonlinearities\n",
      "00:24:30 : Understanding Neural Networks: Basics and Components\n",
      "00:29:09 : Building Neural Networks: From Perceptrons to Layers\n",
      "00:33:46 : Introduction to Neural Networks\n",
      "00:37:12 : Building a Deep Neural Network\n",
      "00:38:11 : Applying Neural Networks to Real Problems\n",
      "00:40:37 : Training Neural Networks\n",
      "00:42:38 : Introduction to Binary Classification and Loss Functions\n",
      "00:49:23 : Gradient Descent and Backpropagation\n",
      "00:53:14 : Understanding Neural Network Loss Landscapes\n",
      "00:58:19 : Optimizers and Learning Rates in Practice\n",
      "00:58:59 : Batching Data for Efficient Training\n",
      "01:02:28 : Understanding Overfitting and Underfitting\n",
      "01:04:28 : Regularization Techniques in Neural Networks\n",
      "01:08:46 : Summary and Transition to Next Lecture\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chapters to Markdown\n",
    "\n",
    "Let us convert the JSON chapters to Markdown format."
   ],
   "metadata": {
    "id": "GJZkjySKyD_W"
   },
   "id": "GJZkjySKyD_W"
  },
  {
   "cell_type": "code",
   "source": [
    "def chapters_to_markdown(chapters):\n",
    "\n",
    "    markdown = \"\"\n",
    "\n",
    "    for i in range(len(chapters)):\n",
    "\n",
    "        chapter = chapters[i]\n",
    "\n",
    "        markdown += f\"# {chapter['title']}\\n\\n\"\n",
    "\n",
    "        for j in range(len(chapter['paragraphs'])):\n",
    "\n",
    "            paragraph = chapter['paragraphs'][j]\n",
    "            start_time = chapter['paragraph_timestamps'][j]\n",
    "            from_to = convert_seconds_to_hms(int(start_time))\n",
    "\n",
    "            markdown += f\"{from_to} - {paragraph}\\n\\n\"\n",
    "\n",
    "    return markdown\n"
   ],
   "metadata": {
    "id": "C5qGstgAyEIw",
    "ExecuteTime": {
     "end_time": "2024-09-09T09:16:45.001562Z",
     "start_time": "2024-09-09T09:16:44.982349Z"
    }
   },
   "id": "C5qGstgAyEIw",
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": [
    "markdown = chapters_to_markdown(chapters)"
   ],
   "metadata": {
    "id": "raJNb93MyoOe",
    "ExecuteTime": {
     "end_time": "2024-09-09T09:17:04.914497Z",
     "start_time": "2024-09-09T09:17:04.910422Z"
    }
   },
   "id": "raJNb93MyoOe",
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ],
   "metadata": {
    "id": "GFta1WQByqQi",
    "ExecuteTime": {
     "end_time": "2024-09-09T09:17:07.298608Z",
     "start_time": "2024-09-09T09:17:07.296881Z"
    }
   },
   "id": "GFta1WQByqQi",
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "source": "printmd(markdown[0:1000])",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nqoXjlZSyqSn",
    "outputId": "ef0b5144-9b3b-4bc7-f0b9-b71904ce241a",
    "ExecuteTime": {
     "end_time": "2024-09-09T09:17:08.270229Z",
     "start_time": "2024-09-09T09:17:08.266721Z"
    }
   },
   "id": "nqoXjlZSyqSn",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# Introduction to the Course\n\n00:00:00 - [Music] Good afternoon, everyone, and welcome to MIT's 6.S191. My name is Alexander Amini, and I'll be one of your instructors for the course this year, along with Ava. Together, we're really excited to welcome you to this incredible course.\n\n00:00:27 - This is a very fast-paced and intense one-week experience that we're about to go through together. We will cover the foundations of a rapidly evolving field that has been changing significantly over the past eight years that we have taught this course at MIT. In fact, over the past decade, even before we started teaching this course, AI and deep learning have been revolutionizing many different areas of science, mathematics, physics, and more.\n\n00:01:05 - Not long ago, we faced challenges and problems that we did not think were necessarily solvable in our lifetimes. Yet, AI is now solving these problems, often surpassing human performance. Each year that we teach this course, this particular lect"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T09:20:13.011205Z",
     "start_time": "2024-09-09T09:20:12.996198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(f\"{DATA_DIR}/{video_id}.md\", \"w\") as f:\n",
    "        f.write(markdown)"
   ],
   "id": "e19e852be5264e12",
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradio app\n",
    "\n",
    "Let us bundle all the stages in a Gradio app"
   ],
   "metadata": {
    "id": "bqc5yYQIo0B3"
   },
   "id": "bqc5yYQIo0B3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T09:45:01.824702Z",
     "start_time": "2024-09-09T09:45:01.813552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import json\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "import utils\n",
    "\n",
    "from openai import OpenAI\n",
    "from groq import Groq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import importlib\n",
    "importlib.reload(utils)\n"
   ],
   "id": "54788ddac1cbf6f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/yalb/Projects/Github/video-chaptering-github/utils.py'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T09:45:03.389232Z",
     "start_time": "2024-09-09T09:45:03.387276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_llm_client_and_model(llm_model):\n",
    "    \n",
    "    if llm_model == \"llama3-8b\":\n",
    "        llm_client = Groq(api_key=GROQ_API_KEY)\n",
    "        llm_model = 'llama3-8b-8192'\n",
    "    \n",
    "    elif llm_model == \"gpt-4o-mini\":\n",
    "        llm_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        llm_model = 'gpt-4o-mini-2024-07-18'\n",
    "    \n",
    "    return llm_client, llm_model\n",
    "        "
   ],
   "id": "e9c999c750cd4af8",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T09:45:06.858674Z",
     "start_time": "2024-09-09T09:45:06.853358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradio_process_video(video_id, \n",
    "                         model_format_transcript, model_toc,\n",
    "                         chunk_size_format_transcript, chunk_size_toc, \n",
    "                         progress=gr.Progress()):\n",
    "    \n",
    "    if video_id in [\"ErnWZxJovaM\"]:\n",
    "        chapters = utils.load_json_chapters(video_id)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
    "    \n",
    "        chunk_size_format_transcript = int(chunk_size_format_transcript)\n",
    "    \n",
    "        llm_client_format_transcript, llm_model_format_transcript = \\\n",
    "            get_llm_client_and_model(model_format_transcript)\n",
    "    \n",
    "        paragraphs, nb_input_tokens, nb_output_tokens, price = \\\n",
    "            utils.transcript_to_paragraphs(transcript,\\\n",
    "                                 llm_client_format_transcript, llm_model_format_transcript,\\\n",
    "                                 chunk_size=chunk_size_format_transcript, progress=progress)\n",
    "\n",
    "        paragraphs = utils.add_timestamps_to_paragraphs(transcript, paragraphs, num_words=50)\n",
    "    \n",
    "        chunk_size_toc = int(chunk_size_toc)\n",
    "        \n",
    "        llm_client_get_toc, llm_model_get_toc = \\\n",
    "            get_llm_client_and_model(model_toc)\n",
    "        \n",
    "        json_toc, nb_input_tokens, nb_output_tokens, price = \\\n",
    "        utils.paragraphs_to_toc(paragraphs, \\\n",
    "                        llm_client_get_toc, llm_model_get_toc, \\\n",
    "                        chunk_size=chunk_size_toc)\n",
    "    \n",
    "        chapters = utils.get_chapters(paragraphs, json_toc)\n",
    "    \n",
    "    output_html = utils.get_result_as_html(chapters, video_id)\n",
    "    \n",
    "    return {output_processing: str(output_html),\n",
    "            gv_output: output_html}\n",
    "    "
   ],
   "id": "b3325f12ef6817c4",
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "source": [
    "css = \"\"\"\n",
    ".content {\n",
    "    padding: 20px;\n",
    "    max-width: 800px;\n",
    "    margin: 0 auto;\n",
    "    background-color: #ffffff;\n",
    "    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "    border-radius: 8px;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "example_video_id = \"ErnWZxJovaM\"\n",
    "example_chapters = utils.load_json_chapters(example_video_id)\n",
    "example_output_html = utils.get_result_as_html(example_chapters, example_video_id)\n",
    "\n",
    "with (gr.Blocks(css=css) as app):\n",
    "\n",
    "    gr.HTML(\"<div align='center'><h1>Demo: Automatic video chaptering with LLMs and TF-IDF</h1></div>\")\n",
    "    gr.HTML(\"<div align='center'><h2>From raw transcript to structured document</h2></div>\")\n",
    "    gr.HTML(\"<div align='center'><h3>See the companion <a href=''>Medium article</a> and <a href=''>Github repository</a> for more details</h3>\")\n",
    "    gr.HTML(\"<hr>\")\n",
    "        \n",
    "    video_id_input = gr.Textbox(label=\"Enter YouTube Video ID\", value = \"ErnWZxJovaM\")\n",
    "    \n",
    "    with gr.Accordion(\"Set parameters\", open=False):\n",
    "            \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                model_format_transcript = gr.Dropdown([(\"LLama 3 8B (Groq)\",\"llama3-8b\"), (\"GPT-4o-mini (OpenAI)\", \"gpt-4o-mini\")], label=\"Transcript preprocessing\", value=\"llama3-8b\", interactive=True)\n",
    "                chunk_size_format_transcript = gr.Textbox(label=\"Preprocessing chunk size\", value = 2000)\n",
    "            with gr.Column(scale=1):\n",
    "                model_toc = gr.Dropdown([(\"LLama 3 8B (Groq)\",\"llama3-8b\"), (\"GPT-4o-mini (OpenAI)\", \"gpt-4o-mini\")], label=\"Chaptering\", value=\"gpt-4o-mini\", interactive=True)\n",
    "                chunk_size_toc = gr.Textbox(label=\"Chaptering chunk size\", value = 30)\n",
    "            with gr.Column(scale=1):\n",
    "                api_key_openai = gr.Textbox(label=\"OpenAI API Key\", value = \"xxx\")\n",
    "                api_key_groq = gr.Textbox(label=\"Groq API Key\", value = \"xxx\")\n",
    "    \n",
    "    processing_button = gr.Button(\"Process transcript\")\n",
    "    \n",
    "    gv_output = gr.State()\n",
    "    \n",
    "    gr.HTML(\"<hr>\")\n",
    "    \n",
    "    output_processing = gr.HTML(label = \"Output processing\", value=example_output_html)\n",
    "    \n",
    "    processing_button.click(gradio_process_video,\n",
    "                            inputs=[video_id_input, \n",
    "                                    model_format_transcript, model_toc,\n",
    "                                    chunk_size_format_transcript, chunk_size_toc],\n",
    "                            outputs=[output_processing, gv_output])\n",
    "\n",
    "app.launch(debug=True, width= \"100%\")"
   ],
   "metadata": {
    "id": "P4GMC275XoRA",
    "ExecuteTime": {
     "end_time": "2024-09-09T10:06:21.571394Z",
     "start_time": "2024-09-09T09:45:15.436300Z"
    }
   },
   "id": "P4GMC275XoRA",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 6\n",
      "i is: 0\n",
      "input tokens: 1044; output tokens: 1053, price: 0.0007884\n",
      "Found paragraphs: 11\n",
      "i is: 5000\n",
      "input tokens: 1075; output tokens: 1110, price: 0.0008272499999999999\n",
      "Found paragraphs: 12\n",
      "i is: 10000\n",
      "input tokens: 1173; output tokens: 1244, price: 0.00092235\n",
      "Found paragraphs: 18\n",
      "i is: 15000\n",
      "input tokens: 1122; output tokens: 1043, price: 0.0007941\n",
      "Found paragraphs: 14\n",
      "i is: 20000\n",
      "input tokens: 1161; output tokens: 1166, price: 0.00087375\n",
      "Found paragraphs: 15\n",
      "i is: 25000\n",
      "input tokens: 686; output tokens: 668, price: 0.0005036999999999999\n",
      "Found paragraphs: 12\n",
      "0\n",
      "input tokens: 3345; output tokens: 169, price: 0.00060315\n",
      "26\n",
      "input tokens: 2787; output tokens: 161, price: 0.00051465\n",
      "54\n",
      "input tokens: 2102; output tokens: 87, price: 0.0003675\n",
      "68\n",
      "input tokens: 868; output tokens: 114, price: 0.0001986\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3c9d5234463a8e2c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a0ac81d2d3441e9b3a5df76a1bd2554": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_625a356a3c03490e94fd7fd4c6735dd5",
       "IPY_MODEL_9eae25c0de28460d8eda4c81f36b12c8",
       "IPY_MODEL_7aaeb859fd084de5a9e0a6a8c457530d"
      ],
      "layout": "IPY_MODEL_638b115d08bb4367a18d8cb83be3eaba"
     }
    },
    "625a356a3c03490e94fd7fd4c6735dd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b85add037e794592a3d10faafed14769",
      "placeholder": "​",
      "style": "IPY_MODEL_e6593af0c76145cb95e70163d8b7aa79",
      "value": "model.bin: 100%"
     }
    },
    "9eae25c0de28460d8eda4c81f36b12c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a037da54f3af40e6a8f2762d39c9223d",
      "max": 3087284237,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e29b8ba4a5034817a48d2467424f922b",
      "value": 3087284237
     }
    },
    "7aaeb859fd084de5a9e0a6a8c457530d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3990513292034aafae131b8045a203e9",
      "placeholder": "​",
      "style": "IPY_MODEL_c1da0bb480624ff0b39f7dd9fc5f9d0e",
      "value": " 3.09G/3.09G [00:13&lt;00:00, 262MB/s]"
     }
    },
    "638b115d08bb4367a18d8cb83be3eaba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b85add037e794592a3d10faafed14769": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6593af0c76145cb95e70163d8b7aa79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a037da54f3af40e6a8f2762d39c9223d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e29b8ba4a5034817a48d2467424f922b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3990513292034aafae131b8045a203e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1da0bb480624ff0b39f7dd9fc5f9d0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "575173787b5c4eb1b445d2dec7bae387": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ec2b1f01be44544bf5a4cb59f4e7499",
       "IPY_MODEL_17a44e75a6414564b01a9f053ebe8687",
       "IPY_MODEL_11b80bf54a9e42bc99d936b63b464dba"
      ],
      "layout": "IPY_MODEL_95a2cbd3dfe346d4a4d5337389a644f2"
     }
    },
    "1ec2b1f01be44544bf5a4cb59f4e7499": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fe82db2540845f985804af8c3712c40",
      "placeholder": "​",
      "style": "IPY_MODEL_12cc093257a5494fa42b75977e79d62c",
      "value": "config.json: 100%"
     }
    },
    "17a44e75a6414564b01a9f053ebe8687": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_328692e5bc6d40178ecc999b374f7632",
      "max": 2394,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_593ff4c702d3449fb4f548bdddbb6977",
      "value": 2394
     }
    },
    "11b80bf54a9e42bc99d936b63b464dba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_974273a5cbb64630b28f49f4622181f1",
      "placeholder": "​",
      "style": "IPY_MODEL_f19d9c65f1cf4af893d71fb2189beb5d",
      "value": " 2.39k/2.39k [00:00&lt;00:00, 47.2kB/s]"
     }
    },
    "95a2cbd3dfe346d4a4d5337389a644f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fe82db2540845f985804af8c3712c40": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12cc093257a5494fa42b75977e79d62c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "328692e5bc6d40178ecc999b374f7632": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "593ff4c702d3449fb4f548bdddbb6977": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "974273a5cbb64630b28f49f4622181f1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f19d9c65f1cf4af893d71fb2189beb5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9346d22a11e4a5dbfc8e265d7603c4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bdb99e3a45464eb4a52d00538f5db3b9",
       "IPY_MODEL_7391cc19998e426288d31a3ad58b67b1",
       "IPY_MODEL_7b8979ebd440484aa62c64a70a95b585"
      ],
      "layout": "IPY_MODEL_ef51ff208ad54d5880fe097273503134"
     }
    },
    "bdb99e3a45464eb4a52d00538f5db3b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87fa8610eb184d06a5fa2525e0221fbf",
      "placeholder": "​",
      "style": "IPY_MODEL_7856dd4417c14c76afd1b8fb3aa2d151",
      "value": "tokenizer.json: 100%"
     }
    },
    "7391cc19998e426288d31a3ad58b67b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6c93bc03f6d4573913b489a73694c54",
      "max": 2480617,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_362358622d4047e8b1fb24a958315a02",
      "value": 2480617
     }
    },
    "7b8979ebd440484aa62c64a70a95b585": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25747c9a3e3e47bc8d1067d65026fa22",
      "placeholder": "​",
      "style": "IPY_MODEL_9e99c0ed5ccb4de9bc67c77d2e805a8a",
      "value": " 2.48M/2.48M [00:00&lt;00:00, 5.01MB/s]"
     }
    },
    "ef51ff208ad54d5880fe097273503134": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87fa8610eb184d06a5fa2525e0221fbf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7856dd4417c14c76afd1b8fb3aa2d151": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6c93bc03f6d4573913b489a73694c54": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "362358622d4047e8b1fb24a958315a02": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "25747c9a3e3e47bc8d1067d65026fa22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e99c0ed5ccb4de9bc67c77d2e805a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de6bb81359e74ab3b26d3ab321d7c789": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_20b2418166fa4d0caa928ac2d390ad78",
       "IPY_MODEL_2b5f0fd2b89c48ebb1b5487691f35411",
       "IPY_MODEL_feca3fad25ac4c4d8c71a3189f0ef1f7"
      ],
      "layout": "IPY_MODEL_69efc6afcfd444ae9ecb9ca5e70e0d5f"
     }
    },
    "20b2418166fa4d0caa928ac2d390ad78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2827314ccbdc49079e3fea36c335b588",
      "placeholder": "​",
      "style": "IPY_MODEL_8329efacee6b4d0bb321b11d56a357c7",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "2b5f0fd2b89c48ebb1b5487691f35411": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92b5ded7cbf4467086af505723ad4e6d",
      "max": 340,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a19f4a06f3374e568acb51007656cea2",
      "value": 340
     }
    },
    "feca3fad25ac4c4d8c71a3189f0ef1f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ad99df8f8b244b3861a49cd66a8de9c",
      "placeholder": "​",
      "style": "IPY_MODEL_160bcbf3fc7e47aa83ac839dcef9e542",
      "value": " 340/340 [00:00&lt;00:00, 10.7kB/s]"
     }
    },
    "69efc6afcfd444ae9ecb9ca5e70e0d5f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2827314ccbdc49079e3fea36c335b588": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8329efacee6b4d0bb321b11d56a357c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92b5ded7cbf4467086af505723ad4e6d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a19f4a06f3374e568acb51007656cea2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6ad99df8f8b244b3861a49cd66a8de9c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "160bcbf3fc7e47aa83ac839dcef9e542": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24a4c950d74a41f29bf8b074dbc2997f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed5fa7711fac4e08b9f3882a269dd612",
       "IPY_MODEL_ca7e477fbecd4d00b29db417663d5d54",
       "IPY_MODEL_4bc292ec121c432f8ce0d71b70c37e30"
      ],
      "layout": "IPY_MODEL_7d596ba8913842a1ba53a37d3b4d6728"
     }
    },
    "ed5fa7711fac4e08b9f3882a269dd612": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5dbed46f7844ea6851b42af3766470f",
      "placeholder": "​",
      "style": "IPY_MODEL_ce34ab0c3707422090e4f801fd927805",
      "value": "vocabulary.json: 100%"
     }
    },
    "ca7e477fbecd4d00b29db417663d5d54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5e7b727f99e4df4a2cc890771230d2f",
      "max": 1068114,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb4794ca6cf742b3880fd16cb26ad28d",
      "value": 1068114
     }
    },
    "4bc292ec121c432f8ce0d71b70c37e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_090f3982133a4bb38a41cae71300389a",
      "placeholder": "​",
      "style": "IPY_MODEL_a552975238a944d8a50d1ddf9400c287",
      "value": " 1.07M/1.07M [00:00&lt;00:00, 6.48MB/s]"
     }
    },
    "7d596ba8913842a1ba53a37d3b4d6728": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5dbed46f7844ea6851b42af3766470f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce34ab0c3707422090e4f801fd927805": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5e7b727f99e4df4a2cc890771230d2f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb4794ca6cf742b3880fd16cb26ad28d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "090f3982133a4bb38a41cae71300389a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a552975238a944d8a50d1ddf9400c287": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
